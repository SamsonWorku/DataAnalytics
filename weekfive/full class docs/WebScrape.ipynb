{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the library used to query a website\n",
    "import urllib.request as urllib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the url\n",
    "wiki = \"https://simple.wikipedia.org/wiki/List_of_U.S._state_capitals\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query the website and return the html to the variable 'page'\n",
    "page = urllib2.urlopen(wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirming that I am connected\n",
    "print(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the Beautiful soup functions to parse the data returned from the website\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse the html in the 'page' variable, and store it in Beautiful Soup format\n",
    "soup = BeautifulSoup(page, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at contents of page - wall of text\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format page contents to include indentation\n",
    "print (soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.<tag>: Return content between opening and closing tag including tag.\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.<tag>.string: Return string within given tag\n",
    "print(soup.title.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shows the first <a> tag on the page\n",
    "soup.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds all <a> tags on the page\n",
    "soup.find_all(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show hyperlink reference for all <a> tags\n",
    "all_links=soup.find_all(\"a\")\n",
    "for link in all_links:\n",
    "    print (link.get(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fina all the <table> tags\n",
    "all_tables=soup.find_all('table')\n",
    "all_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the <table> tag that contains the data we want to scrap\n",
    "#.find_all or .findall(?) for all tables\n",
    "right_table=soup.find('table', class_='wikitable sortable')\n",
    "right_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate lists\n",
    "A=[]\n",
    "B=[]\n",
    "C=[]\n",
    "D=[]\n",
    "E=[]\n",
    "F=[]\n",
    "G=[]\n",
    "H=[]\n",
    "I=[]\n",
    "J=[]\n",
    "K=[]\n",
    "\n",
    "#\n",
    "for row in right_table.findAll(\"tr\"):\n",
    "    cells = row.findAll('td')\n",
    "    if len(cells)==11: #Only extract table body not heading\n",
    "        A.append(cells[0].find(text=True)) #gets info in State column and adds it to list A\n",
    "        B.append(cells[1].find(text=True)) # gets info from Abr. column and adds it to list B\n",
    "        C.append(cells[2].find(text=True)) # gets info from Statehood column; add it to list C\n",
    "        D.append(cells[3].find(text=True)) # gets info from Capital column and adds it to list D\n",
    "        E.append(cells[4].find(text=True)) # gets info from Capital since column and adds it to list E\n",
    "        F.append(cells[5].find(text=True)) # gets info from Area column and adds it to list F\n",
    "        G.append(cells[6].find(text=True)) # gets info from Municipal column and adds it to list G\n",
    "        H.append(cells[7].find(text=True)) # gets info from Metropolitan column and adds it to list H\n",
    "        I.append(cells[8].find(text=True)) # gets info from Rank in State column and adds it to list I\n",
    "        J.append(cells[9].find(text=True)) # gets info from Rank in US column and adds it to list J\n",
    "        K.append(cells[10].find(text=True)) # gets info from Notes column and adds it to list K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show data in list A, just to check (first five entries)\n",
    "A[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas to convert list to data frame\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame(A, columns=['State']) #turn list A into dataframe first\n",
    "\n",
    "#add other lists as new columns\n",
    "df['Abr'] = B\n",
    "df['Statehood'] = C\n",
    "df['Capital'] = D\n",
    "df['Capital_Since'] = E\n",
    "df['Area'] = F\n",
    "df['Municipal'] = G\n",
    "df['Metropolitan'] = H\n",
    "df['Rank in US'] = I\n",
    "df['Rank in US'] = J\n",
    "df['Notes'] = K\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export our scraped data to a file\n",
    "df.to_csv(\"CapitalList.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
